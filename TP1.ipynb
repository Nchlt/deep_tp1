{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOT3u0GZKWc8"
   },
   "source": [
    "# Réseau de neurones: les bases en numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Irgrskx6KWc-"
   },
   "source": [
    "Le but de ce TP1 est d'acquérir les bases nécessaires à la compréhension des réseaux de neurones à partir d'un modèle simple de type Softmax. La tâche d'apprentissage consiste à classifier les images (28 par 28 pixels) de la base MNIST (http://yann.lecun.com/exdb/mnist/) en 10 catégories représentant les chiffres 0-9.\n",
    "\n",
    "Le TP2 consistera à généraliser les concepts de ce TP1 à un réseau de neurones multi-couches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlmi-culKWdA"
   },
   "source": [
    "## Téléchargement de la base d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "B9Ekg9fkKWdD"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnistfile=\"mnist.pkl.gz\"\n",
    "\n",
    "## If you need to download it : \n",
    "##if(\"mnist.pkl.gz\" not in os.listdir(\".\")):\n",
    "    #!wget http://deeplearning.net/data/mnist/mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Z209vjgKWdI"
   },
   "source": [
    "## Chargement de la base en mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 758,
     "status": "error",
     "timestamp": 1539027170049,
     "user": {
      "displayName": "Xihui Wang",
      "photoUrl": "",
      "userId": "09445164112052208872"
     },
     "user_tz": -120
    },
    "id": "mpsZNRC7KWdJ",
    "outputId": "62717275-e711-44e0-eafa-990e62d7a244"
   },
   "outputs": [],
   "source": [
    "import dataset_loader\n",
    "train_set, valid_set, test_set = dataset_loader.load_mnist(mnistfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6omnBvnBKWdM"
   },
   "source": [
    "Vous pouvez visualiser les différents caractères en changeant l'identifiant de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vaeu6ApKWdN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/EBQhB8IivADQRF+ICjCDwRF+IGg/h9G1+coNnZL8gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105edcba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 42\n",
    "plt.imshow(train_set[0][img_id].reshape(28,28),cmap='Greys')\n",
    "print(\"label: \" + str(train_set[1][img_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GNRQzPZ3KWdP"
   },
   "source": [
    "**Question:** Donner les caractéristiques de la base d'apprentissage train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Agfwh-s8KWdQ"
   },
   "outputs": [],
   "source": [
    "def getDimDataset(train_set):\n",
    "    n_training = train_set[0].shape[0]\n",
    "    n_feature = train_set[0].shape[1]\n",
    "    n_label = len(np.unique(train_set[1]))\n",
    "    return n_training, n_feature, n_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NeDu0nO6KWdT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getDimDataset(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvZIFXNNKWdV"
   },
   "source": [
    "## Création du modèle\n",
    "\n",
    "Nous allons d'abord créer une couche linéaire, soit une transformation linéaire. La vraie difficulté réside dans la manipulation de matrices de ne pas se mélanger dans les dimensions. \n",
    "\n",
    "Pour l'implémentation, nous allons considérer explicitement le terme de biais. Ainsi, une couche linéaire se définit comme la tranformation linéaire: \n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{W}\\mathbf{x}+ \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Notons *n_in* et *n_out* respectivement les dimensions de $\\mathbf{x}$ et $\\mathbf{y}$. \n",
    "\n",
    "**Questions:**\n",
    "- écrire les dimensions de W et b\n",
    "- Coder la fonction d'init. suivante, l'init. est aléatoire et gaussienne, comme dans le cours. La fonction retourne W et b. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse**\n",
    "\n",
    "W contient pour chaque neurone de la couche considérée, tous les poids venant des neurones de la couche précédente donc W à pour dimensions n_out * n_in.\n",
    "Si on a le même biais pour tous les neurones de la couche alors b est un scalaire. Sinon \n",
    "il a la taille de la couche actuelle, donc n_out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zaHamy9hKWdX"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def init(n_in, n_out):\n",
    "    W = np.random.standard_normal(size=(n_out, n_in))\n",
    "    b = np.random.standard_normal(n_out)\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "79A7J5vYKWdZ"
   },
   "source": [
    "**Test:** Même si cela ne sera pas redit, on vérifie toujours les dimensions de ce que l'on crée, et transforme. Dit autrement on fait des tests intermédiaires. En machine learning, comme en programmation, c'est incontournable. \n",
    "Pour cela créer, une couche de tailles d'entrée et de sortie égales à 5 et 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4MGDedaKWda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W dimensions : (3, 5)\n",
      "b dimensions : (3,)\n"
     ]
    }
   ],
   "source": [
    "W_test, b_test = init(5, 3)\n",
    "print(\"W dimensions : \"+str(W_test.shape))\n",
    "print(\"b dimensions : \"+str(b_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Whj07Lr5KWdc"
   },
   "source": [
    "**Question :** Donner les dimensions de W et b ainsi que le nombre total de paramètres du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrvS_bs1KWdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W dimensions: 15\n",
      "b dimensions: 3\n",
      "Number of parameters: 18\n"
     ]
    }
   ],
   "source": [
    "def printInfo(W,b):\n",
    "    W_dim = np.asarray(W.shape).prod()\n",
    "    print(\"W dimensions: \" + str(W_dim))\n",
    "    print(\"b dimensions: \" + str(len(b)))\n",
    "    print(\"Number of parameters: \" + str(W_dim + len(b)))\n",
    "printInfo(W_test, b_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "euHVEX4iKWdf"
   },
   "source": [
    "**Question:** Implémenter la fonction forward tel que $$y_j = \\sum_{i \\rightarrow j} W_{ij} x_i + b_j$$ où $x_i$ est un pixel de l'image, $W_{ij}$ est la valeur associée à l'arête reliant les unités $i$ et $j$ et $b_j$ est le biais associé à l'unité $j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "emgTpnkOKWdf"
   },
   "outputs": [],
   "source": [
    "def forward(W,b,X):\n",
    "    \"\"\"\n",
    "        Perform the forward propagation\n",
    "        :param W: the weights\n",
    "        :param b: the bias\n",
    "        :param X: the input (minibatch_size x n_input)\n",
    "        :type W: ndarray\n",
    "        :type B: ndarray\n",
    "        :type X: ndarray\n",
    "        :return: the transformed values\n",
    "        :rtype: ndarray\n",
    "    \"\"\"\n",
    "    return np.sum(W.T * X[:,:,None] + b, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_test shape: (3, 5)\n",
      "b_test shape: (3,)\n",
      "X_test shape: (10, 5)\n",
      "forward shape:(10, 3)\n",
      "One ex shape: (3,)\n",
      "[[ 4.66606015 -6.22848973 -0.38715523]\n",
      " [ 4.28929511 -4.03634463 -1.06220996]\n",
      " [ 4.61631554 -6.07541054 -1.44357031]\n",
      " [ 4.43193072 -5.15556455 -1.02307299]\n",
      " [ 3.24695536 -5.14121517 -0.32914087]\n",
      " [ 4.13202838 -5.68934534 -1.04114215]\n",
      " [ 4.87955976 -5.19409114 -0.59719171]\n",
      " [ 4.92248049 -6.02026635 -1.36140506]\n",
      " [ 5.09104882 -4.94707676 -0.68779855]\n",
      " [ 4.50902319 -6.41610503 -1.15860473]]\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "import random\n",
    "minibatch_size = 10\n",
    "X_test = np.asarray([random.random() \n",
    "                     for _ in range(50)]).reshape(10, 5)\n",
    "fwd = forward(W_test, b_test, X_test)\n",
    "print(\"W_test shape: \"+str(W_test.shape))\n",
    "print(\"b_test shape: \"+str(b_test.shape))\n",
    "print(\"X_test shape: \"+str(X_test.shape))\n",
    "print(\"forward shape:\"+str(fwd.shape))\n",
    "print(\"One ex shape: \"+str(fwd[0].shape))\n",
    "print(fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gITyvKlJKWdh"
   },
   "source": [
    "** Question:** Implémenter la fonction softmax $$ \\sigma_i = \\frac{\\exp{a_i}}{\\sum_k \\exp{a_k}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RP7zNrrKWdh"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# Activation function\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "        Perform the softmax transformation to the pre-activation values\n",
    "        :param a: the pre-activation values\n",
    "        :type a: ndarray\n",
    "        :return: the activation values\n",
    "        :rtype: ndarray\n",
    "    \"\"\"\n",
    "    res = np.exp(z - np.max(z))\n",
    "    return res / res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dj3H212KWdj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Example for testing the numerical stability of softmax\n",
    "# It should return [1., 0. ,0.], not [nan, 0., 0.]\n",
    "z = [1000000,1,100]\n",
    "print(softmax(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "(10, 3)\n",
      "[[  1.08546557e-01   2.01452731e-06   6.93477697e-04]\n",
      " [  7.44713241e-02   1.80388845e-05   3.53069299e-04]\n",
      " [  1.03279053e-01   2.34776490e-06   2.41122234e-04]\n",
      " [  8.58884834e-02   5.89031669e-06   3.67161322e-04]\n",
      " [  2.62607228e-02   5.97544840e-06   7.34899265e-04]\n",
      " [  6.36339680e-02   3.45398616e-06   3.60586603e-04]\n",
      " [  1.34380965e-01   5.66769872e-06   5.62101593e-04]\n",
      " [  1.40274262e-01   2.48086667e-06   2.61770784e-04]\n",
      " [  1.66029893e-01   7.25577389e-06   5.13410520e-04]\n",
      " [  9.27717539e-02   1.66990924e-06   3.20624155e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Test \n",
    "print(fwd.shape)\n",
    "s_fwd = softmax(fwd)\n",
    "print(s_fwd.shape)\n",
    "print(s_fwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oeBggY-AKWdj"
   },
   "source": [
    "**Question:** Vérifier que votre implémentation de softmax soit numériquement stable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xFXYu0gtKWdl"
   },
   "source": [
    "** Question: ** Si le softmax s'avère instable, comment le rendre stable ? Proposer une implémentation stable du softmax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7LYky4LfKWdm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4BKLEUkNKWdo"
   },
   "source": [
    "**Question:** Implémenter le calcul du gradient de l'erreur par rapport à $a_i$:\n",
    "$$\\delta a_i = \\sigma_i - 1_{i=l}$$\n",
    "où $l$ est l'étiquette associée à la donnée courante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JNKTNt3gKWdp"
   },
   "outputs": [],
   "source": [
    "def gradient_out(out, one_hot_batch):\n",
    "    \"\"\"\n",
    "    compute the gradient w.r.t. the pre-activation values of the softmax z_i\n",
    "    :param out: the softmax values\n",
    "    :type out: ndarray 10,3\n",
    "    :param one_hot_batch: the one-hot representation of the labels\n",
    "    :type one_hot_batch: ndarray\n",
    "    :return: the gradient w.r.t. z\n",
    "    :rtype: ndarray\n",
    "    \"\"\"\n",
    "    return out - one_hot_encoded\n",
    "\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    \"\"\"\n",
    "    Compute the one hot encoded representation of the given labels\n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for label in labels:\n",
    "        enc_label = [0 for _ in range(10)]\n",
    "        enc_label[label] = 1\n",
    "        res.append(enc_label)\n",
    "    return np.asarray(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de shape\n",
      "(100,)\n",
      "(100, 10)\n",
      "Test de valeurs\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[[1 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Test one_hot_encode \n",
    "print(\"Test de shape\")\n",
    "labels_test = np.asarray([random.randint(0,9) for _ in range(100)])\n",
    "print(labels_test.shape)\n",
    "hot_labels = one_hot_encode(labels_test)\n",
    "print(hot_labels.shape)\n",
    "print(\"Test de valeurs\")\n",
    "labels_test_2 = [i for i in range(10)]\n",
    "print(labels_test_2)\n",
    "print(one_hot_encode(labels_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-WxLD1nKWds"
   },
   "source": [
    "**Question:** Implémenter la fonction du calcul de gradient par rapport aux paramètres: $$\\delta W_{ij} = \\delta a_j x_i$$  $$\\delta b_{j} = \\delta a_j$$ où $\\delta W_{ij}$ est la composante du gradient associée à l'arête reliant les unités $i$ et $j$, $\\delta b_{j}$ est la composante du gradient associée au bias de l'unité $j$, $\\delta z_j$ est le gradient de l'erreur par rapport à l'unité $j$ et $x_i$ est la valeur d'activation de l'unité $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hDB7Vc7nKWds"
   },
   "outputs": [],
   "source": [
    "def gradient(derror, X):\n",
    "    \"\"\"\n",
    "        Compute the gradient w.r.t. the parameters\n",
    "        :param derror: the gradient w.r.t. z\n",
    "        :param X: the input (minibatch_size x n_input)\n",
    "        :param minibatch_size: the minibatch size\n",
    "        :type derror: ndarray\n",
    "        :type minibatch: ndarray\n",
    "        :type minibatch_size: unsigned\n",
    "        :return: the gradient w.r.t. the parameters\n",
    "        :rtype: ndarray, ndarray\n",
    "    \"\"\"\n",
    "    #grad_w = np.zeros((derror.shape[0],X.shape[1]))\n",
    "    grad_w = np.sum((derror * X[:,:,None]), axis=1)\n",
    "    #grad_b = np.zeros((derror.shape[0]))\n",
    "    grad_b = \n",
    "    return grad_w, grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBSv8LIlKWdu"
   },
   "source": [
    "**Question:** Implémenter la fonction de mise à jour des paramètres $$\\theta = \\theta - \\eta \\delta \\theta$$ où $\\theta$ est un paramètre du modèle et $\\delta \\theta$ la composante du gradient associée à $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RnPLmd-iKWdv"
   },
   "outputs": [],
   "source": [
    "def update(eta, W, b, grad_w, grad_b):\n",
    "    \"\"\"\n",
    "        Update the parameters with an update rule\n",
    "        :param eta: the step-size\n",
    "        :param W: the weights\n",
    "        :param b: the bias\n",
    "        :param grad_w: the gradient w.r.t. the weights\n",
    "        :param grad_b: the gradient w.r.t. the bias\n",
    "        :type eta: float\n",
    "        :type W: ndarray\n",
    "        :type b: ndarray\n",
    "        :type grad_w: ndarray\n",
    "        :type grad_b: ndarray\n",
    "        :return: the updated parameters\n",
    "        :rtype: ndarray, ndarray\n",
    "    \"\"\"\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hzcMLu1KKWdx"
   },
   "source": [
    "## Algorithme d'apprentissage \n",
    "\n",
    "On a tout ce qu'il faut pour mettre en oeuvre l'apprentissage d'un modèle simple. Le modèle est simplement une couche neuronale de sortie, sans couche cachée. \n",
    "\n",
    "L'algorithme se déroule en 2 temps, tout d'abord la préparation: \n",
    "- init. du modèle\n",
    "- préparation des données et des variables permettant de stocker l'historique d'apprentissage\n",
    "- init. des paramètres de la SGD\n",
    "- définir le nombre d'époque comme une variable\n",
    "\n",
    "Puis vient la boucle d'apprentissage qui pour chaque époque effectue pour chaque exemple d'apprentissage : \n",
    "- inférence du modèle sur l'exemple d'apprentissage \n",
    "- calcul de la contribution de l'exemple à la  fonction objectif, et également au taux d'erreur de classification\n",
    "- Calcul du gradient de sortie\n",
    "- Mise à jour du modèle\n",
    "\n",
    "** Question: ** Implémenter l'apprentissage du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2y1-MKzmKWdy"
   },
   "outputs": [],
   "source": [
    "# à vous de jouer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZEhLDilKWd0"
   },
   "source": [
    "**Question:** Si vous stockez correctement les informations, vous pouvez tracer l'évolution du taux d'erreur et de la fonction objectif au cours du temps. Cette étape est loin d'être illustrative, elle est indispensable pour vérifier si l'apprentissage se passe bien. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m6m06X92KWd1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwFi9mTCKWd4"
   },
   "source": [
    "**Question:** Inclure dans votre code, le calcul du taux d'erreur et de la fonction objectif sur les données de validation (cela doit faire l'objet du fonction à part). Représenter les évolutions également et les comparer avec celles observées sur les données d'apprentissage. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sZNcuF2kKWd5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzzIlowPKWd6"
   },
   "source": [
    "**Question:** Montrer, à l'aide d'une figure, l'effet du step-size (prendre $\\eta$=[0.01,0.1,1.0,10.]) sur les courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LadSNtxsKWd7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TP1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
